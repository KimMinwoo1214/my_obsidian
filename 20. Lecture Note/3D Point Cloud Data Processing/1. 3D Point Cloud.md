---
tags:
  - AI
  - CV
  - PointCloud
  - SLAM
aliases: 
type: lecture-note
created: 2024-07-18
reviewed: false
notices: false
summary: false
---
### **Subject**:: [[3D Point Cloud Data Processing]]
### **Week**:: 1

**이전 강의 노트**: [[]]

### 강의자료: 
[강의 영상](https://youtu.be/nSVOSIUYna4)
스터디 교재 (p.1 ~ 12) 
[참고자료1](https://www.youtube.com/watch?v=QsfybIs774o) 
[참고자료2](https://www.youtube.com/watch?v=vfL6uJYFrp4&t=402s)
<br/>

# 강의필기 (Lecture Notes)

## 3D Point Cloud Data의 특성

- 다학제적 접근 필요: 컴퓨터 비전, 머신러닝, 컴퓨터 그래픽스, 디퍼런셜 지오메트리 등

### [[ComputerVision]]

**컴퓨터 비전**은 사람의 시각 인지 시스템을 모사하여 기계가 시각적인 정보를 바탕으로 본 대상을 이해하거나 추론할 수 있는 시스템을 의미합니다. 이 시스템은 주로 디지털 이미지나 비디오에서 정보를 추출하여 처리합니다.

### 주요 작업

- **쉐이프 어널리시스(Shape Analysis)**: 객체의 모양을 분석하여 인식.
- **에지 디텍션(Edge Detection)**: 이미지에서 객체의 경계를 식별.
- **패턴 클래스피케이션(Pattern Classification)**: 특정 패턴을 인식하고 분류.

### 3D 컴퓨터 비전

3D 컴퓨터 비전은 컴퓨터 비전의 한 가지 브랜치로, 3차원 데이터를 다룹니다. 전통적인 컴퓨터 비전은 3차원 공간의 정보를 2D 이미지로 프로젝션하여 분석하는 반면, 3D 컴퓨터 비전은 다양한 센서로 직접 획득한 3차원 데이터를 사용합니다.

### 3D 데이터 획득 방법

- **스테레오 이미지(Stereo Images)**: 두 개 이상의 이미지를 사용하여 깊이 정보를 추출.
- **멀티뷰 지오메트리(Multiview Geometry)**: 여러 뷰포인트에서 촬영된 이미지를 통해 3D 구조를 재구성.
- **RGBD 카메라**: RGB 이미지와 깊이 정보를 동시에 획득.
- **라이더(LiDAR)**: 레이저를 사용하여 3차원 점군(Point Cloud) 데이터를 실시간으로 획득.

### [[Explicit Surface Presentation]]

이 방법에서는 3차원 형상의 위치, 거리, 노멀 벡터와 같은 형상 정보를 직접적으로 명시합니다.

### 예시: 원주 표현

- **익스플리시트한 방법**:
    - 원주를 x,y 좌표로 명시.
        
        x,yx, y
        
    - 예: 반지름이 1인 원주를 0,1,−1,0 등으로 표현.
        
        0,1,−1,00, 1, -1, 0
        
    - 스플라인, 삼각형 메쉬, 포인트 등을 이용하여 형상 정보 직접 표현.
        
    - **장점**: 형상 수정이 용이.
        

### [[Implicit Surface Presentation]]

이 방법에서는 3차원 서페이스를 수학적 함수로 표현하여, 함수의 특정 값(예: 0)이 서페이스를 나타내는 방식입니다.

### 예시: 원주 표현

- **인플리시트한 방법**:
    - 원주를 수학적 함수로 정의.
        
    - 예: 
	    $$
	    x^2 + y^2 - 1 = 0
	    $$
        
        
    - 함수가 0이 되는 지점이 서페이스를 나타냄.
        
    - **장점**: 복잡한 서페이스 형상 표현이 용이.
        

<br/>

## [[기초 개념/Point Cloud|Point Cloud]]

포인트 클라우드는 3차원 공간상의 점들의 위치 정보를 모아놓은 데이터셋입니다.

### 포인트 클라우드의 특징

- **표현 방식**: 서로 직교하는 세 축 x,y,z의 좌표로 3차원 벡터 형태로 표현.
    
    x,y,zx, y, z
    
- **데이터 크기**: 수십 개에서 수백만 개의 포인트로 구성.
    
- **추가 정보**:
    
    - **RGBD 카메라**: x,y,z,R,G,B 형태로 색상 정보 포함.
        
        x,y,z,R,G,Bx, y, z, R, G, B
        
    - **노멀 벡터**: x,y,z,nx,ny,nz 형태로 법선 벡터 포함.
        
        x,y,z,nx,ny,nzx, y, z, nx, ny, nz
        
    - **기타 피처**: 주어 매트릭 특징 등을 벡터 스페이스로 임베딩.
        

### [[Point Cloud]] vs. 2D [[Image]]

#### 2D 이미지

- **구조화**: 2차원 평면에 구조화된 데이터.
- **해상도**: 픽셀 해상도로 표현.
- **예시**: 1024x768 해상도의 이미지.

#### 포인트 클라우드

- **비구조화**: 데이터에 순서가 없고, 비구조화된 형태. (Permutational Invariant)
- **밀도**: 데이터 밀도는 불균일.
    - **Dense Region**: 포인트가 밀집된 영역.
    - **Sparse Region**: 포인트가 드문드문한 영역.
- **노이즈 포함 가능성**: 아웃라이어 및 노이즈 포함 가능.

#### **데이터 처리 방법 차이**

- **2D 이미지:**
    - 구조화된 데이터를 바탕으로 간단한 처리 가능.
    - 예: 컨볼루션 연산.
- **포인트 클라우드:**
    - 비구조화된 데이터를 다루기 위해 복잡한 처리 방법 필요.
    - 예: Neighbor Search 등을 통한 이웃 점 찾기.

### Point Cloud의 순서 불변성 및 딥러닝 적용

#### 포인트 클라우드의 순서 불변성 (Commutational Invariance)

- **순서의 불변성**:
    - 포인트 클라우드는 데이터 저장 순서가 달라도 동일한 형상을 나타낼 수 있음.
    - 예: 한 데이터셋은 상단부터 시작하고 다른 데이터셋은 하단부터 시작해도 동일한 형상 표현.
    - **의미**: 데이터의 순서가 달라도 동일한 결과를 도출해야 함.
    - **필요성**: 순서가 바뀌어도 동일하게 처리할 수 있는 알고리즘과 데이터 구조 필요.

#### 딥러닝의 적용

- **2D 이미지에서의 딥러닝**:
    - **컨볼루션 연산**: 2D 이미지 데이터는 구조화된 픽셀 배열로, CNN (Convolutional Neural Network)에 잘 맞음.
    - **적용 용이성**: 이미지 데이터는 CNN 구조와 잘 맞아 다양한 딥러닝 백본을 활용할 수 있음.
    - **성숙한 기술**: CNN 기반 딥러닝 기법은 높은 성능을 발휘하며 많이 활용됨.
- **3D 포인트 클라우드에서의 딥러닝**:
    - **도전 과제**:
        - 비구조화된 데이터: 포인트 클라우드는 구조가 없고, 포인트 간의 연결 정보도 없음.
        - 일레귤러한 특성: 포인트 밀도가 불균일하고 노이즈 포함 가능성.
    - **기존 CNN의 적용 한계**: 3D 포인트 클라우드는 CNN에 직접 적용하기 어려움.
    - **대안 기법들**:
        - **복셀화(Voxelization)**:
            - 포인트 클라우드를 3D 그리드로 변환.
            - 3D 컨볼루션 적용 가능.
        - **2D 평면 프로젝션**:
            - 특정 평면으로 포인트 클라우드를 투영하여 2D 이미지 형태로 변환.
            - 기존의 2D CNN 구조 활용 가능.
        - **포인트 클라우드 전용 Neural Network**:
            - 포인트넷(PointNet) 등, 포인트 클라우드의 특성을 고려한 네트워크 아키텍처 설계.
            - 순서 불변성, 비구조화된 특성을 처리할 수 있도록 설계.

#### RGBD 데이터

- **RGBD 카메라**:
    - RGB 이미지와 깊이 정보를 함께 제공.
    - **예**: 마이크로소프트의 키넥트.
    - **구성**: RGB 채널(3채널) + Depth 정보.
    - **포인트 클라우드 변환**: 깊이 정보를 이용해 3D 포인트 클라우드 생성 가능.
- **장점**:
    - **2D와 3D 데이터 동시 활용**:
        - 2D 이미지 처리 기법과 3D 포인트 클라우드 처리 기법을 동시에 활용 가능.
        - 2D CNN과 같은 기존 기법을 그대로 사용할 수 있음.
    - **다양한 응용**:
        - 증강현실(AR), 가상현실(VR), 로보틱스 등에서 활용 가능.
<br/>

### [[3D Data Expression]]
![[Pasted image 20240721180740.png]]

#### 복셀(Voxel) 데이터

- **설명**:
    - 2D 픽셀의 3D 버전으로, 3차원 공간을 큐브 형태의 격자로 표현.
    - 각 복셀은 특정 위치에서의 점유 정보를 나타냄.
- **예시**:
    - 3차원 큐브 형태의 어큐펀스 그리드로 표현.
    - 포인트 클라우드를 복셀 구조로 변환하여 샘플링 수행.
- **장점**:
    - **구조화된 데이터**: 복셀은 구조화된 데이터로, 다양한 컨볼루션 연산 적용이 용이.
    - **유니폼 표현**: 벽면, 천장 등 포인트 클라우드의 밀집도를 유니폼하게 표현.
- **단점**:
    - **계산 시간**: 포인트 클라우드를 복셀로 변환하는 데 시간이 소요됨.
    - **데이터 손실**: 변환 과정에서 데이터가 손실될 수 있음.
    - **메모리 요구량**: 높은 해상도를 위해서는 많은 메모리 필요.

#### 메시(Mesh) 데이터

- **설명**:
    - 포인트 클라우드의 각 점을 삼각형이나 사각형으로 연결하여 표면을 구성.
    - 각 점 간의 연결성을 나타내며, 3D 형상의 연속적인 표면을 표현.
- **예시**:
    - 트라이앵글 메쉬, 커드라틱 메쉬 등으로 표현.
    - 주변 데이터의 군집 및 밀집 분석.
- **장점**:
    - **연속적 서페이스 표현**: 포인트 클라우드에 비해 형상을 연속적으로 표현 가능.
    - **연결성 정보**: 포인트와 포인트 사이의 연결성 정보가 포함되어 있음.
    - **랜더링 용이**: 랜더링 작업에 유리함.
- **단점**:
    - **매싱 과정**: 포인트 클라우드를 메시로 변환하는 과정에서 최적화 문제 발생.
    - **추가 프로세싱 필요**: 메시 데이터로 변환하는 추가 작업 필요.
<br/>

### [[Point Cloud]] Data Processing

#### 전통적 포인트 클라우드 처리 기법

##### 1. 레지스트레이션(Registration)
![[Pasted image 20240721181031.png]]

- **설명**: 두 개의 포인트 클라우드를 정렬하여 하나의 좌표계로 맞추는 과정.
- **목적**: 다양한 각도에서 스캔한 데이터를 하나의 3D 모델로 통합.
- **방법**:
    - **리지드 트랜스포메이션**: 회전(rotation)과 이동(translation)만 적용.
    - **논리지드 트랜스포메이션**: 형상 변환(deformation) 포함.
- **예시**: 두 개의 서로 다른 부분을 스캔한 3D 물체의 포인트 클라우드를 정렬하여 하나의 완벽한 3D 모델 생성.

##### 2. 클래스피케이션(Classification)
![[Pasted image 20240721181051.png]]

- **설명**: 포인트 클라우드를 특정 클래스에 분류하는 작업.
- **목적**: 포인트 클라우드가 어떤 물체인지를 식별.
- **방법**:
    - 전통적 방법: 특징점(feature) 추출 후 머신러닝 기법 적용.
    - 딥러닝 기법: 엔드투엔드(end-to-end) 방식으로 특징 추출과 분류를 동시에 수행.
- **예시**: 주어진 포인트 클라우드가 체어, 테이블, 모니터 등으로 분류.

##### 3. 시맨틱 세그멘테이션(Semantic Segmentation)

- **설명**: 포인트 클라우드의 각 포인트에 클래스 레이블을 부여.
- **목적**: 포인트 클라우드의 각 부분에 대해 더 높은 수준의 이해를 제공.
- **방법**: 딥러닝 기법을 사용하여 각 포인트에 클래스 레이블을 예측.
- **예시**: 자율주행 차량의 라이다 데이터에서 도로, 차량, 자전거 등의 레이블을 부여.

##### 4. 오브젝트 디텍션(Object Detection)

- **설명**: 포인트 클라우드에서 물체의 위치와 크기를 검출.
- **목적**: 3D 공간에서 객체의 위치와 종류를 식별.
- **방법**: 시맨틱 세그멘테이션 후 바운딩 박스를 추론하여 물체 검출.
- **예시**: 자율주행 환경에서 차량, 이륜차, 보행자를 검출하여 위치와 크기를 예측.

##### 5. 오도메트리(Odometry)

- **설명**: 이동 경로상에서 위치 정보를 추론.
- **목적**: 이동체의 위치와 경로를 추적.
- **방법**:
    - GPS나 IMU를 이용한 전통적 기법.
    - 카메라나 3D 센서를 이용한 비주얼 오도메트리, 라이더 오도메트리.
- **예시**: 360도 라이더를 이용하여 실시간으로 3D 공간 정보를 맵핑하고 이동체의 위치를 추적.

#### 딥러닝 기반 포인트 클라우드 처리 기법

딥러닝 기반의 방법들은 전통적 방법에 비해 성능이 우수하지만, 좋은 데이터셋을 확보하는 것이 중요합니다. 또한, 포인트 클라우드의 비구조화된 특성을 처리할 수 있는 딥러닝 모델이 필요합니다.

##### 1. 포인트넷(PointNet)

- **설명**: 포인트 클라우드를 직접 입력으로 사용하는 신경망 아키텍처.
- **특징**: 포인트 간의 순서에 불변하도록 설계되어 포인트 클라우드 데이터의 특성을 잘 처리.

##### 2. 복셀넷(VoxelNet)

- **설명**: 포인트 클라우드를 복셀로 변환하여 3D CNN을 적용하는 기법.
- **특징**: 3D 컨볼루션을 사용하여 포인트 클라우드를 처리.

##### 3. 2D 평면 프로젝션

- **설명**: 포인트 클라우드를 특정 평면으로 투영하여 2D 이미지 형태로 변환.
- **특징**: 기존의 2D CNN 구조를 그대로 활용 가능.

#### 포인트 클라우드 데이터셋

포인트 클라우드의 처리 기법을 연구하고 벤치마킹하기 위해 다양한 데이터셋이 공개되고 있습니다.

##### 대표 데이터셋

- **모델넷(ModelNet)**: CAD 모델을 기반으로 생성된 포인트 클라우드 데이터셋으로, 주로 객체 분류와 모양 검색에 사용.
- **쉐이프넷(ShapeNet)**: CAD 모델에서 추출한 포인트 클라우드로, 객체 분류와 파트 세그멘테이션에 최적화.
- **스탠퍼드 3D 인도어 세그멘테이션**: RGBD 카메라로 획득한 인도어 데이터셋으로, 시맨틱 세그멘테이션에 사용.
- **3D 매치(3DMatch)**: 두 포인트 클라우드 간의 레지스트레이션을 위한 데이터셋.
- **키티(KITTI) 데이터셋**: 자율주행 환경에서 획득한 데이터셋으로, 2D 및 3D 오도메트리, 객체 검출, 시맨틱 세그멘테이션에 사용.

## 공지사항
<br>



## 수업 내용


# 다음 할 일(After Actions)
## 작업 (Tasks)


## 정리 (Summary)

### Pros and Cons of 3D Point Clouds
	- Strengths
		- The most common 3D data acquired by 3D sensors(stereo, RGB-D, LiDAR)
		- 3D information with no depth ambiguity (explicit)
		- Mathematically simple and concise
	- Weakness
		- Irregular (dense and sparse region)
		- Unstructured and No grid
		- Unordered (permitation invariant)
	- Processing: registration, classification, segmentation, odometry
	- Applications: autonomous driving, AR & VR, robotics, etc.

